# [íŠ¹ë³„ ê¸°íš] Scrapling: ì°¨ì„¸ëŒ€ ì ì‘í˜• ì›¹ ìŠ¤í¬ë˜í•‘ í”„ë ˆì„ì›Œí¬ â€” ì² ë„ PHM ë°ì´í„° ìˆ˜ì§‘ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„

**Date**: 2026-02-27  
**Category**: Special Report / Web Scraping / Data Engineering  
**Tags**: #Scrapling #WebScraping #AntiBot #DataCollection #RailwayPHM #Automation #Python

---

## Executive Summary

ì˜¤ëŠ˜ GitHub Trending 1ìœ„ë¥¼ ì°¨ì§€í•œ **Scrapling**(2,902 stars/day)ì€ ë‹¨ìˆœí•œ ì›¹ ìŠ¤í¬ë˜í•‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë„˜ì–´, **ì ì‘í˜• ìš”ì†Œ ì¶”ì **, **Cloudflare Turnstile ìš°íšŒ**, **ë©€í‹°ì„¸ì…˜ í¬ë¡¤ë§**, **ì¼ì‹œì •ì§€/ì¬ê°œ ê¸°ëŠ¥**ì„ ê°–ì¶˜ ì°¨ì„¸ëŒ€ ë°ì´í„° ìˆ˜ì§‘ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

ì² ë„/ì„¤ë¹„ PHM ì—°êµ¬ìì—ê²ŒëŠ” **ì™¸ë¶€ ë²¤ë” API ì—†ì´** í•™ìˆ  ë…¼ë¬¸ ë©”íƒ€ë°ì´í„°, ì„¼ì„œ ë°ì´í„° ì•„ì¹´ì´ë¸Œ, ê³µê³µ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œë¥¼ ìë™ ìˆ˜ì§‘í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤.

**í•µì‹¬ ê°€ì¹˜**:
- ğŸ•·ï¸ **Scrapy ìˆ˜ì¤€ì˜ í”„ë¡œë•ì…˜ í¬ë¡¤ëŸ¬** + BeautifulSoup ìˆ˜ì¤€ì˜ ê°„ê²°í•¨
- ğŸ›¡ï¸ **Cloudflare Turnstile ìë™ ìš°íšŒ** (StealthyFetcher)
- ğŸ”„ **ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ì—ë„ ìë™ ì ì‘** (Adaptive Element Tracking)
- âš¡ **Parsel/Scrapy ëŒ€ë¹„ ë™ê¸‰ ì„±ëŠ¥**, BS4 ëŒ€ë¹„ ~784ë°° ë¹ ë¦„
- ğŸ¤– **MCP ì„œë²„ ë‚´ì¥** â€” Claude/Cursorì™€ AI í˜‘ì—… ê°€ëŠ¥

---

## 1. ì™œ ì§€ê¸ˆ í•«í•œê°€? (Why Now?)

### 1.1 í­ë°œì  ì„±ì¥ ì§€í‘œ
- **ì˜¤ëŠ˜ í•˜ë£¨ +2,902 ìŠ¤íƒ€** (2026-02-27 ê¸°ì¤€)
- **ì´ 17,272 ìŠ¤íƒ€**, 1,141 í¬í¬
- **92% í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€** + ì „ì²´ íƒ€ì… íŒíŠ¸ (PyRight/MyPy)
- **ê³µì‹ Docker ì´ë¯¸ì§€** ìë™ ë°°í¬ (GitHub Actions)

### 1.2 ì‹œì¥ ë§¥ë½: ì›¹ ìŠ¤í¬ë˜í•‘ì˜ 3ëŒ€ ê³ ì§ˆë³‘ í•´ê²°
1. **Anti-bot ì¥ë²½ ê³ ë„í™”**  
   - Cloudflare Turnstile, reCAPTCHA v3 ë“±ìœ¼ë¡œ ê¸°ì¡´ Scrapy/Selenium ë¬´ë ¥í™”  
   - Scraplingì€ **TLS fingerprint spoofing** + **headless browser detection ìš°íšŒ**ë¡œ ëŒ€ì‘

2. **ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ì— ì·¨ì•½í•œ ì„ íƒì(selector)**  
   - ê¸°ì¡´: CSS/XPath ì„ íƒìê°€ ê¹¨ì§€ë©´ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨  
   - Scrapling: **ì ì‘í˜• ìš”ì†Œ ì¶”ì **(Adaptive Element Tracking)ìœ¼ë¡œ ìë™ ì¬íƒìƒ‰

3. **ëŒ€ê·œëª¨ í¬ë¡¤ë§ì˜ ë³µì¡ì„±**  
   - ê¸°ì¡´: Scrapy ì„¤ì • ë³µì¡, Seleniumì€ ë™ì‹œì„± ë¶€ì¡±  
   - Scrapling: **Scrapy API + ë¸Œë¼ìš°ì € ìë™í™” í†µí•©** + ë©€í‹°ì„¸ì…˜ ê´€ë¦¬

---

## 2. ê¸°ìˆ  ìŠ¤íƒ & ì•„í‚¤í…ì²˜

### 2.1 3-Layer Fetcher ì•„í‚¤í…ì²˜
```python
from scrapling.fetchers import Fetcher, StealthyFetcher, DynamicFetcher

# Layer 1: HTTP ìš”ì²­ (ë¹ ë¦„, TLS ìœ„ì¥)
page = Fetcher.get('https://example.com', impersonate='chrome')

# Layer 2: Stealth ëª¨ë“œ (Cloudflare ìš°íšŒ)
page = StealthyFetcher.fetch('https://protected.site', solve_cloudflare=True)

# Layer 3: í’€ ë¸Œë¼ìš°ì € ìë™í™” (Playwright)
page = DynamicFetcher.fetch('https://dynamic.site', network_idle=True)
```

| ë ˆì´ì–´ | ì—”ì§„ | ì†ë„ | Anti-bot ìš°íšŒ | ì‚¬ìš© ì¼€ì´ìŠ¤ |
|--------|------|------|---------------|-------------|
| **Fetcher** | httpx + TLS spoofing | âš¡âš¡âš¡ | Medium | ì •ì  í˜ì´ì§€, API ì—”ë“œí¬ì¸íŠ¸ |
| **StealthyFetcher** | Playwright + Stealth Plugin | âš¡âš¡ | High | Cloudflare, reCAPTCHA |
| **DynamicFetcher** | Playwright (full control) | âš¡ | Highest | SPA, ë¬´í•œ ìŠ¤í¬ë¡¤, WebSocket |

### 2.2 Scrapy-Style Spider API
```python
from scrapling.spiders import Spider, Response

class QuotesSpider(Spider):
    name = "quotes"
    start_urls = ["https://quotes.toscrape.com/"]
    concurrent_requests = 10

    async def parse(self, response: Response):
        for quote in response.css('.quote'):
            yield {
                "text": quote.css('.text::text').get(),
                "author": quote.css('.author::text').get(),
            }
        next_page = response.css('.next a')
        if next_page:
            yield response.follow(next_page[0].attrib['href'])

result = QuotesSpider(crawldir="./data").start()
result.items.to_json("quotes.json")
```

**í”„ë¡œë•ì…˜ ê¸°ëŠ¥**:
- âœ… **Pause/Resume**: Ctrl+Cë¡œ ì¼ì‹œì •ì§€, ì¬ì‹œì‘ ì‹œ ìë™ ì¬ê°œ
- âœ… **Streaming Mode**: `async for item in spider.stream()`ìœ¼ë¡œ ì‹¤ì‹œê°„ ì²˜ë¦¬
- âœ… **Blocked Request Detection**: ìë™ ì¬ì‹œë„ + ì»¤ìŠ¤í…€ ë¡œì§
- âœ… **Per-Domain Throttling**: ë„ë©”ì¸ë³„ ìš”ì²­ ì œí•œ

### 2.3 ì ì‘í˜• ìš”ì†Œ ì¶”ì  (Adaptive Element Tracking)
```python
# ì´ˆê¸° ìŠ¤í¬ë˜í•‘
products = page.css('.product', auto_save=True)  # ìš”ì†Œ íŒ¨í„´ ì €ì¥

# ì›¹ì‚¬ì´íŠ¸ ë¦¬ë‰´ì–¼ í›„ (í´ë˜ìŠ¤ëª…ì´ '.product' â†’ '.item-card'ë¡œ ë³€ê²½)
products = page.css('.product', adaptive=True)  # ìë™ìœ¼ë¡œ ìƒˆ ì„ íƒì ì¶”ë¡ !
```

**ì‘ë™ ì›ë¦¬**:
1. `auto_save=True`ë¡œ ìš”ì†Œì˜ **êµ¬ì¡°ì  íŠ¹ì§•**(íƒœê·¸, ì†ì„±, í…ìŠ¤íŠ¸ íŒ¨í„´) ì €ì¥
2. ì„ íƒì ì‹¤íŒ¨ ì‹œ **ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜**(Levenshtein, TF-IDF)ìœ¼ë¡œ í›„ë³´ ì¬íƒìƒ‰
3. ë§¤ì¹­ ì„±ê³µ ì‹œ ìƒˆ ì„ íƒì ìë™ ì €ì¥

---

## 3. ì‹¤ë¬´ ì ìš© í¬ì¸íŠ¸: ì² ë„ PHM ë°ì´í„° ìˆ˜ì§‘

### 3.1 Use Case 1: arXiv ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ìë™ ìˆ˜ì§‘
**í˜„ì¬ ë¬¸ì œì **:
- arXiv APIëŠ” rate limit (ì´ˆë‹¹ 1ìš”ì²­) + ë©”íƒ€ë°ì´í„°ë§Œ ì œê³µ
- ë…¼ë¬¸ ë³¸ë¬¸ PDFëŠ” ë³„ë„ ë‹¤ìš´ë¡œë“œ í•„ìš”
- Cloudflare ì ìš© ì‹œ ì¼ë°˜ ìŠ¤í¬ë˜í¼ ì°¨ë‹¨

**Scrapling ì†”ë£¨ì…˜**:
```python
from scrapling.spiders import Spider, Response

class ArxivSpider(Spider):
    name = "arxiv_phm"
    start_urls = ["https://arxiv.org/search/?query=railway+PHM&order=-announced_date_first"]
    
    async def parse(self, response: Response):
        for paper in response.css('.arxiv-result'):
            arxiv_id = paper.css('.list-title a::text').get()
            title = paper.css('.title::text').get()
            authors = paper.css('.authors a::text').getall()
            abstract = paper.css('.abstract-full::text').get()
            
            # PDF ë‹¤ìš´ë¡œë“œ ìš”ì²­ ìƒì„±
            pdf_url = f"https://arxiv.org/pdf/{arxiv_id}.pdf"
            yield response.follow(pdf_url, callback=self.save_pdf, meta={'arxiv_id': arxiv_id})
            
            yield {
                'arxiv_id': arxiv_id,
                'title': title,
                'authors': authors,
                'abstract': abstract
            }
```

**ì¥ì **:
- âœ… Cloudflare ìš°íšŒ (StealthyFetcher ì‚¬ìš© ì‹œ)
- âœ… ë™ì‹œì„± 10+ë¡œ ì†ë„ 10ë°° í–¥ìƒ
- âœ… ì¼ì‹œì •ì§€/ì¬ê°œë¡œ ë„¤íŠ¸ì›Œí¬ ì¥ì•  ë³µêµ¬

### 3.2 Use Case 2: KORAIL ê³µê³µ ë°ì´í„° í¬í„¸ í¬ë¡¤ë§
**ì‹œë‚˜ë¦¬ì˜¤**: ì² ë„ ì‚¬ê³  ì´ë ¥, ì°¨ëŸ‰ ì ê²€ ìŠ¤ì¼€ì¤„ ë“± ê³µê°œ ë°ì´í„° ìë™ ìˆ˜ì§‘

```python
class KorailDataSpider(Spider):
    name = "korail_public"
    start_urls = ["https://example.korail.com/data"]
    
    def configure_sessions(self, manager):
        # ë¹ ë¥¸ í˜ì´ì§€ëŠ” HTTP, ë³´í˜¸ëœ í˜ì´ì§€ëŠ” Stealth
        manager.add("fast", FetcherSession(impersonate="chrome"))
        manager.add("stealth", AsyncStealthySession(headless=True), lazy=True)
    
    async def parse(self, response: Response):
        for row in response.css('table.data-table tr'):
            if 'protected' in row.css('a::attr(href)').get():
                yield Request(row.css('a::attr(href)').get(), sid="stealth")
            else:
                yield Request(row.css('a::attr(href)').get(), sid="fast")
```

**ë¹„ìš© ì ˆê°**:
- ì™¸ë¶€ API ë¹„ìš© $0 (ì§ì ‘ ìˆ˜ì§‘)
- ì¸ë ¥ íˆ¬ì… ì‹œê°„ 90% ê°ì†Œ (ìë™í™”)

### 3.3 Use Case 3: ì„¤ë¹„ ì§„ë‹¨ ë²¤ë” ëŒ€ì‹œë³´ë“œ ë°±ì—…
**ì‹œë‚˜ë¦¬ì˜¤**: ì™¸ì£¼ ì§„ë‹¨ ì—…ì²´ì˜ ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ ì„¼ì„œ ë°ì´í„° ìë™ ë°±ì—…

```python
from scrapling.fetchers import DynamicSession

with DynamicSession(headless=True) as session:
    # ë¡œê·¸ì¸
    page = session.fetch('https://vendor-dashboard.com/login')
    page.fill('input[name="username"]', 'your_id')
    page.fill('input[name="password"]', 'your_pw')
    page.click('button[type="submit"]')
    
    # ë°ì´í„° í˜ì´ì§€ ì´ë™
    page = session.fetch('https://vendor-dashboard.com/sensor-data', network_idle=True)
    data = page.css('.sensor-reading').getall()
```

**ì¥ì **:
- âœ… ë²¤ë” ì¢…ì†ì„± ì œê±° (ë°ì´í„° ì£¼ê¶Œ í™•ë³´)
- âœ… ìì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê°€ëŠ¥

---

## 4. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬: "ì–¼ë§ˆë‚˜ ë¹ ë¥¸ê°€?"

### 4.1 íŒŒì‹± ì†ë„ ë¹„êµ (100+ runs í‰ê· )
| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ì‹œê°„ (ms) | vs Scrapling |
|-----------|-----------|--------------|
| **Scrapling** | **2.02** | **1.0x** |
| Parsel/Scrapy | 2.04 | 1.01x |
| Raw Lxml | 2.54 | 1.26x |
| PyQuery | 24.17 | ~12x |
| Selectolax | 82.63 | ~41x |
| BS4 (Lxml) | 1584.31 | **~784x** |
| BS4 (html5lib) | 3391.91 | ~1679x |

### 4.2 ì ì‘í˜• ìš”ì†Œ ì°¾ê¸° ì†ë„
| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ì‹œê°„ (ms) | vs Scrapling |
|-----------|-----------|--------------|
| **Scrapling** | **2.39** | **1.0x** |
| AutoScraper | 12.45 | 5.2x |

**ê²°ë¡ **: Scrapy/Parsel ìˆ˜ì¤€ì˜ ì†ë„ + BeautifulSoup ìˆ˜ì¤€ì˜ ê°„ê²°í•¨

---

## 5. ë¦¬ìŠ¤í¬ & í•œê³„

### 5.1 ë²•ì /ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­
âš ï¸ **robots.txt ì¤€ìˆ˜ í•„ìˆ˜**:
```python
# robots.txtë¥¼ ë¬´ì‹œí•˜ë©´ ë²•ì  ì±…ì„ ë°œìƒ ê°€ëŠ¥
Spider.respect_robots_txt = True  # ê¸°ë³¸ê°’: True
```

âš ï¸ **ê°œì¸ì •ë³´ ìˆ˜ì§‘ ê¸ˆì§€**:
- GDPR, CCPA ìœ„ë°˜ ì‹œ ë²Œê¸ˆ ìµœëŒ€ 2ì²œë§Œ ìœ ë¡œ
- ì² ë„ ìŠ¹ê° ë°ì´í„°, ë¯¼ê° ì •ë³´ëŠ” ì ˆëŒ€ ìˆ˜ì§‘ ê¸ˆì§€

### 5.2 ê¸°ìˆ ì  í•œê³„
1. **JavaScript ë Œë”ë§ ë¹„ìš©**  
   - DynamicFetcherëŠ” Playwright ê¸°ë°˜ â†’ CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ  
   - í•´ê²°ì±…: StealthyFetcher ìš°ì„  ì‹œë„, ì‹¤íŒ¨ ì‹œì—ë§Œ DynamicFetcher

2. **Cloudflare ìš°íšŒ ë¶ˆì™„ì „**  
   - Turnstile v3ëŠ” ìš°íšŒ ê°€ëŠ¥, ìµœì‹  v4ëŠ” ì¼ë¶€ ì‹¤íŒ¨  
   - í•´ê²°ì±…: `solve_cloudflare=True` + í”„ë¡ì‹œ ë¡œí…Œì´ì…˜ ë³‘í–‰

3. **ëŒ€ê·œëª¨ í¬ë¡¤ë§ ì‹œ IP ì°¨ë‹¨ ìœ„í—˜**  
   - í•´ê²°ì±…: `ProxyRotator` + per-domain delay ì„¤ì •
   ```python
   Spider.download_delay = 1.0  # ë„ë©”ì¸ë‹¹ 1ì´ˆ ëŒ€ê¸°
   ```

---

## 6. MALT ì—…ë¬´ ê´€ì  ì•¡ì…˜ì•„ì´í…œ

### 6.1 ë‹¨ê¸° (1ê°œì›”)
âœ… **Notion RAG ë°ì´í„° ë°±ì—… ìë™í™”**  
- í˜„ì¬: ìˆ˜ë™ìœ¼ë¡œ Notion API í˜¸ì¶œ  
- ê°œì„ : Scraplingìœ¼ë¡œ ì›¹ UI ì§ì ‘ í¬ë¡¤ë§ (API ì œí•œ ìš°íšŒ)

```python
class NotionBackupSpider(Spider):
    name = "notion_backup"
    start_urls = ["https://www.notion.so/your-workspace"]
    
    async def parse(self, response: Response):
        for page_link in response.css('a.notion-page-link'):
            yield response.follow(page_link.attrib['href'], callback=self.save_page)
```

### 6.2 ì¤‘ê¸° (3ê°œì›”)
âœ… **ì™¸ë¶€ í•™ìˆ  ìë£Œ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•**  
- arXiv, IEEE Xplore, ScienceDirectì—ì„œ CBM/PHM ë…¼ë¬¸ ìë™ ìˆ˜ì§‘  
- ì¼ì£¼ì¼ì— 1íšŒ ìë™ ì‹¤í–‰ (cron) + Notion ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸

### 6.3 ì¥ê¸° (6ê°œì›”)
âœ… **KORAIL ë‚´ë¶€ ëŒ€ì‹œë³´ë“œ ë°ì´í„° í†µí•©**  
- ì™¸ì£¼ ì—…ì²´ 5ê°œì˜ ë³„ë„ ì›¹ ëŒ€ì‹œë³´ë“œ â†’ ë‹¨ì¼ ë°ì´í„° ë ˆì´í¬ë¡œ í†µí•©  
- Scrapling + Airflowë¡œ ETL íŒŒì´í”„ë¼ì¸ ìë™í™”

---

## 7. ì„¤ì¹˜ & ë¹ ë¥¸ ì‹œì‘

### 7.1 ê¸°ë³¸ ì„¤ì¹˜
```bash
pip install "scrapling[all]"
scrapling install  # ë¸Œë¼ìš°ì € ë‹¤ìš´ë¡œë“œ (Chromium, Firefox)
```

### 7.2 1ë¶„ ë§Œì— ì‹œì‘í•˜ê¸°
```python
from scrapling.fetchers import StealthyFetcher

# Cloudflare ë³´í˜¸ëœ ì‚¬ì´íŠ¸ í¬ë¡¤ë§
page = StealthyFetcher.fetch('https://nopecha.com/demo/cloudflare', solve_cloudflare=True)
data = page.css('#padded_content a').getall()
print(data)
```

### 7.3 Dockerë¡œ ì‹¤í–‰
```bash
docker pull pyd4vinci/scrapling
docker run -it pyd4vinci/scrapling python -c "from scrapling.fetchers import Fetcher; print(Fetcher.get('https://example.com').css('h1::text').get())"
```

---

## 8. ê²½ìŸ ë„êµ¬ ë¹„êµ

| ê¸°ëŠ¥ | Scrapling | Scrapy | Selenium | Playwright |
|------|-----------|--------|----------|------------|
| **Cloudflare ìš°íšŒ** | âœ… ë‚´ì¥ | âŒ í”ŒëŸ¬ê·¸ì¸ í•„ìš” | âš ï¸ ë¶ˆì™„ì „ | âš ï¸ ìˆ˜ë™ ì„¤ì • |
| **ì ì‘í˜• ì„ íƒì** | âœ… | âŒ | âŒ | âŒ |
| **ì¼ì‹œì •ì§€/ì¬ê°œ** | âœ… | âš ï¸ ì»¤ìŠ¤í…€ í•„ìš” | âŒ | âŒ |
| **íŒŒì‹± ì†ë„** | âš¡âš¡âš¡ | âš¡âš¡âš¡ | âš¡ | âš¡âš¡ |
| **í•™ìŠµ ê³¡ì„ ** | ë‚®ìŒ | ì¤‘ê°„ | ë‚®ìŒ | ì¤‘ê°„ |
| **MCP ì„œë²„** | âœ… | âŒ | âŒ | âŒ |

**ê²°ë¡ **: Scrapyì˜ ê²¬ê³ í•¨ + Seleniumì˜ ìœ ì—°í•¨ + Playwrightì˜ í˜„ëŒ€ì„± = **Scrapling**

---

## 9. ê²°ë¡ : ë°ì´í„° ìˆ˜ì§‘ì˜ ìƒˆë¡œìš´ í‘œì¤€

Scraplingì€ ë‹¨ìˆœíˆ "ë˜ í•˜ë‚˜ì˜ ìŠ¤í¬ë˜í•‘ ë¼ì´ë¸ŒëŸ¬ë¦¬"ê°€ ì•„ë‹™ë‹ˆë‹¤. **ì›¹ ìŠ¤í¬ë˜í•‘ì˜ 3ëŒ€ ë‚œì œ**(anti-bot, êµ¬ì¡° ë³€ê²½, ëŒ€ê·œëª¨ í¬ë¡¤ë§)ë¥¼ í•œ ë²ˆì— í•´ê²°í•œ **ì°¨ì„¸ëŒ€ ë°ì´í„° ìˆ˜ì§‘ í”Œë«í¼**ì…ë‹ˆë‹¤.

ì² ë„/ì„¤ë¹„ PHM ì—°êµ¬ìì—ê²ŒëŠ”:
- âœ… **ì™¸ë¶€ API ì¢…ì† íƒˆí”¼** (ë°ì´í„° ì£¼ê¶Œ í™•ë³´)
- âœ… **ì—°êµ¬ ì‹œê°„ ë‹¨ì¶•** (ìˆ˜ë™ ìˆ˜ì§‘ â†’ ìë™í™”)
- âœ… **ë¹„ìš© ì ˆê°** (ë²¤ë” API ë¹„ìš© $0)

**ë‹¤ìŒ ìŠ¤í…**:
1. ì‘ì€ í”„ë¡œì íŠ¸ë¡œ ì‹œì‘ (arXiv ë…¼ë¬¸ 10ê±´ ìˆ˜ì§‘)
2. í”„ë¡œë•ì…˜ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (Airflow + Scrapling)
3. íŒ€ ë‚´ í‘œì¤€ ë„êµ¬ë¡œ ë„ì…

**ê³µì‹ ë¬¸ì„œ**: [https://scrapling.readthedocs.io](https://scrapling.readthedocs.io)  
**GitHub**: [https://github.com/D4Vinci/Scrapling](https://github.com/D4Vinci/Scrapling) (â­ 17,272)

---

*ì´ ë¦¬í¬íŠ¸ëŠ” 2026-02-27 GitHub Trending ë°ì´í„° ë° ê³µì‹ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
